{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a141da58",
   "metadata": {},
   "source": [
    "Data Collection:\n",
    "\n",
    "-Using PyBaseball package to collect pitch data from 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e0b0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cpim1\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "from pybaseball import statcast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4590f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import os\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "import io\n",
    "import sys\n",
    "import contextlib\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pybaseball import statcast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf9c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Quiet mode\n",
    "# -------------------------------\n",
    "# Disable tqdm progress bars used internally\n",
    "os.environ[\"TQDM_DISABLE\"] = \"1\"\n",
    "# Silence pybaseball/pandas FutureWarnings etc.\n",
    "warnings.filterwarnings(\"ignore\", module=\"pybaseball\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _suppress_stdout_stderr():\n",
    "    \"\"\"Temporarily redirect stdout/stderr to devnull (tqdm writes to stderr).\"\"\"\n",
    "    with open(os.devnull, 'w') as devnull:\n",
    "        old_out, old_err = sys.stdout, sys.stderr\n",
    "        try:\n",
    "            sys.stdout = devnull\n",
    "            sys.stderr = devnull\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_out\n",
    "            sys.stderr = old_err\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Config\n",
    "# -------------------------------\n",
    "TRAIN_RANGES: List[Tuple[date, date]] = [\n",
    "    (date(2021, 4, 1),  date(2021, 10, 3)),\n",
    "    (date(2022, 4, 7),  date(2022, 10, 5)),\n",
    "    (date(2023, 3, 30), date(2023, 10, 1)),\n",
    "    (date(2024, 3, 28), date(2024, 9, 29)),\n",
    "]\n",
    "TEST_RANGES: List[Tuple[date, date]] = [\n",
    "    (date(2025, 3, 27), date(2025, 8, 31)),\n",
    "]\n",
    "\n",
    "CHUNK_DAYS = 5\n",
    "REQUEST_SLEEP_SEC = 1.0\n",
    "MAX_RETRIES = 3\n",
    "RETRY_SLEEP_SEC = 3.0\n",
    "\n",
    "OUTPUT_DIR = \"output\"\n",
    "TRAIN_OUT = os.path.join(OUTPUT_DIR, \"train.csv\")\n",
    "TEST_OUT  = os.path.join(OUTPUT_DIR, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c6332ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Utilities\n",
    "# -------------------------------\n",
    "def generate_chunks(start_date: date, end_date: date, span_days: int = CHUNK_DAYS) -> List[Tuple[date, date]]:\n",
    "    chunks = []\n",
    "    cur = start_date\n",
    "    delta = timedelta(days=span_days - 1)\n",
    "    while cur <= end_date:\n",
    "        nxt = min(cur + delta, end_date)\n",
    "        chunks.append((cur, nxt))\n",
    "        cur = nxt + timedelta(days=1)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def fetch_statcast_window(start_dt: str, end_dt: str) -> pd.DataFrame:\n",
    "    last_err = None\n",
    "    for _ in range(MAX_RETRIES):\n",
    "        try:\n",
    "            with _suppress_stdout_stderr():\n",
    "                return statcast(start_dt=start_dt, end_dt=end_dt)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(RETRY_SLEEP_SEC)\n",
    "    # On permanent failure return empty frame silently\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "def collect_ranges(ranges: List[Tuple[date, date]]) -> pd.DataFrame:\n",
    "    frames = []\n",
    "    for s, e in ranges:\n",
    "        for a, b in generate_chunks(s, e, CHUNK_DAYS):\n",
    "            df = fetch_statcast_window(a.strftime(\"%Y-%m-%d\"), b.strftime(\"%Y-%m-%d\"))\n",
    "            if df is not None and not df.empty:\n",
    "                frames.append(df)\n",
    "            time.sleep(REQUEST_SLEEP_SEC)\n",
    "    if not frames:\n",
    "        return pd.DataFrame()\n",
    "    out = pd.concat(frames, ignore_index=True)\n",
    "    if \"game_date\" in out.columns:\n",
    "        out[\"game_date\"] = pd.to_datetime(out[\"game_date\"], errors=\"coerce\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_vaa_row(row: pd.Series) -> float:\n",
    "    for k in (\"vy0\", \"ay\", \"vz0\", \"az\"):\n",
    "        if pd.isna(row.get(k)):\n",
    "            return np.nan\n",
    "    vy0, ay, vz0, az = row[\"vy0\"], row[\"ay\"], row[\"vz0\"], row[\"az\"]\n",
    "    if pd.isna(vy0) or pd.isna(ay) or pd.isna(vz0) or pd.isna(az) or ay == 0:\n",
    "        return np.nan\n",
    "    y0, yf = 50.0, 17.0 / 12.0\n",
    "    vy_f_sq = vy0**2 - 2.0 * ay * (y0 - yf)\n",
    "    if vy_f_sq < 0:\n",
    "        return np.nan\n",
    "    vy_f = -np.sqrt(vy_f_sq)\n",
    "    t = (vy_f - vy0) / ay\n",
    "    if not np.isfinite(t) or t <= 0:\n",
    "        return np.nan\n",
    "    vz_f = vz0 + az * t\n",
    "    if vy_f == 0:\n",
    "        return np.nan\n",
    "    return float(-np.degrees(np.arctan(vz_f / vy_f)))\n",
    "\n",
    "\n",
    "def add_vaa(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df[\"vaa\"] = df.apply(compute_vaa_row, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def sort_and_dedup(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    sort_cols = [c for c in [\"game_date\", \"game_pk\", \"at_bat_number\", \"pitch_number\"] if c in df.columns]\n",
    "    if sort_cols:\n",
    "        df = df.sort_values(sort_cols, kind=\"mergesort\")\n",
    "    dedup_keys = [c for c in [\"game_pk\", \"at_bat_number\", \"pitch_number\"] if c in df.columns]\n",
    "    if dedup_keys:\n",
    "        df = df.drop_duplicates(subset=dedup_keys, keep=\"first\")\n",
    "    else:\n",
    "        df = df.drop_duplicates(keep=\"first\")\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44628fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote 2,844,586 rows to output\\train.csv\n",
      "✅ Wrote 599,491 rows to output\\test.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Main\n",
    "# -------------------------------\n",
    "def main():\n",
    "    ensure_dir(TRAIN_OUT)\n",
    "    ensure_dir(TEST_OUT)\n",
    "\n",
    "    # TRAIN\n",
    "    train_df = collect_ranges(TRAIN_RANGES)\n",
    "    train_df = add_vaa(train_df)\n",
    "    train_df = sort_and_dedup(train_df)\n",
    "    train_df.to_csv(TRAIN_OUT, index=False)\n",
    "    print(f\"✅ Wrote {len(train_df):,} rows to {TRAIN_OUT}\")\n",
    "\n",
    "    # TEST\n",
    "    test_df = collect_ranges(TEST_RANGES)\n",
    "    test_df = add_vaa(test_df)\n",
    "    test_df = sort_and_dedup(test_df)\n",
    "    test_df.to_csv(TEST_OUT, index=False)\n",
    "    print(f\"✅ Wrote {len(test_df):,} rows to {TEST_OUT}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "654c98ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: c:\\Users\\cpim1\\Downloads\n",
      "File: C:\\Users\\cpim1\\Downloads\\output\\train.csv\n",
      "Exists? True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "print(\"CWD:\", Path.cwd())\n",
    "p = Path(\"output/train.csv\").resolve()\n",
    "print(\"File:\", p)\n",
    "print(\"Exists?\", p.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a275c86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pitch_type', 'game_date', 'release_speed', 'release_pos_x', 'release_pos_z', 'player_name', 'batter', 'pitcher', 'events', 'description', 'spin_dir', 'spin_rate_deprecated', 'break_angle_deprecated', 'break_length_deprecated', 'zone', 'des', 'game_type', 'stand', 'p_throws', 'home_team', 'away_team', 'type', 'hit_location', 'bb_type', 'balls', 'strikes', 'game_year', 'pfx_x', 'pfx_z', 'plate_x', 'plate_z', 'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot', 'hc_x', 'hc_y', 'tfs_deprecated', 'tfs_zulu_deprecated', 'umpire', 'sv_id', 'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az', 'sz_top', 'sz_bot', 'hit_distance_sc', 'launch_speed', 'launch_angle', 'effective_speed', 'release_spin_rate', 'release_extension', 'game_pk', 'fielder_2', 'fielder_3', 'fielder_4', 'fielder_5', 'fielder_6', 'fielder_7', 'fielder_8', 'fielder_9', 'release_pos_y', 'estimated_ba_using_speedangle', 'estimated_woba_using_speedangle', 'woba_value', 'woba_denom', 'babip_value', 'iso_value', 'launch_speed_angle', 'at_bat_number', 'pitch_number', 'pitch_name', 'home_score', 'away_score', 'bat_score', 'fld_score', 'post_away_score', 'post_home_score', 'post_bat_score', 'post_fld_score', 'if_fielding_alignment', 'of_fielding_alignment', 'spin_axis', 'delta_home_win_exp', 'delta_run_exp', 'bat_speed', 'swing_length', 'estimated_slg_using_speedangle', 'delta_pitcher_run_exp', 'hyper_speed', 'home_score_diff', 'bat_score_diff', 'home_win_exp', 'bat_win_exp', 'age_pit_legacy', 'age_bat_legacy', 'age_pit', 'age_bat', 'n_thruorder_pitcher', 'n_priorpa_thisgame_player_at_bat', 'pitcher_days_since_prev_game', 'batter_days_since_prev_game', 'pitcher_days_until_next_game', 'batter_days_until_next_game', 'api_break_z_with_gravity', 'api_break_x_arm', 'api_break_x_batter_in', 'arm_angle', 'attack_angle', 'attack_direction', 'swing_path_tilt', 'intercept_ball_minus_batter_pos_x_inches', 'intercept_ball_minus_batter_pos_y_inches', 'vaa']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"output/train.csv\")\n",
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee57800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CH', 'CS', 'CU', 'EP', 'FA', 'FC', 'FF', 'FO', 'FS', 'KC', 'KN', 'PO', 'SC', 'SI', 'SL', 'ST', 'SV']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_pitches = sorted(df[\"pitch_type\"].dropna().unique().tolist())\n",
    "print(unique_pitches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "168510c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_CH', 'is_CS', 'is_CU', 'is_EP', 'is_FA', 'is_FC', 'is_FF', 'is_FO', 'is_FS', 'is_KC', 'is_KN', 'is_PO', 'is_SC', 'is_SI', 'is_SL', 'is_ST', 'is_SV']\n",
      "is_FF    943637\n",
      "is_SL    463671\n",
      "is_SI    439453\n",
      "is_CH    309426\n",
      "is_FC    216939\n",
      "is_CU    196284\n",
      "is_ST    131946\n",
      "is_FS     60803\n",
      "is_KC     60486\n",
      "is_SV     11907\n",
      "dtype: uint64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load & normalize\n",
    "df = pd.read_csv(\"output/train.csv\")\n",
    "pt = (df[\"pitch_type\"]\n",
    "        .astype(\"string\")\n",
    "        .str.strip()\n",
    "        .str.upper())\n",
    "\n",
    "# (optional) normalize ambiguous labels\n",
    "# pt = pt.replace({\"ST\": \"SV\", \"FA\": \"FF\"})\n",
    "\n",
    "# one-hot to binary flags named is_*\n",
    "dummies = pd.get_dummies(pt, prefix=\"is\", dtype=\"uint8\")   # columns like is_FF, is_SI, ...\n",
    "df = df.join(dummies)\n",
    "\n",
    "# quick check\n",
    "print(sorted([c for c in df.columns if c.startswith(\"is_\")]))\n",
    "print(df.filter(like=\"is_\").sum().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e083f0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['babip_value', 'p_L', 'p_R', 'p_<NA>']\n",
      "['at_bat_number', 'bat_score', 'post_bat_score', 'bat_speed', 'bat_score_diff', 'bat_win_exp', 'age_bat_legacy', 'bat_L', 'bat_R', 'bat_<NA>']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"output/train.csv\")\n",
    "\n",
    "# normalize text\n",
    "for c in [\"p_throws\", \"stand\"]:\n",
    "    df[c] = df[c].astype(\"string\").str.strip().str.upper()\n",
    "\n",
    "# one-hot (includes a column for NaN)\n",
    "df_enc = pd.get_dummies(df, columns=[\"p_throws\", \"stand\"], prefix=[\"p\", \"bat\"], dummy_na=True)\n",
    "\n",
    "print(df_enc.filter(like=\"p_\").columns.tolist())\n",
    "print(df_enc.filter(like=\"bat_\").columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "132d7835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p_throws\n",
       "R    2060796\n",
       "L     783790\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"p_throws\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a4b9ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    R\n",
       "1    R\n",
       "2    R\n",
       "3    R\n",
       "4    R\n",
       "5    R\n",
       "6    R\n",
       "7    R\n",
       "8    R\n",
       "9    R\n",
       "Name: p_throws, dtype: string"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) First 10 values (with index)\n",
    "df[\"p_throws\"].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b3bf8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  p_throws  is_R  is_L\n",
      "0        R     1     0\n",
      "1        R     1     0\n",
      "2        R     1     0\n",
      "3        R     1     0\n",
      "4        R     1     0\n",
      "5        R     1     0\n",
      "6        R     1     0\n",
      "7        R     1     0\n",
      "8        R     1     0\n",
      "9        R     1     0\n",
      "R count: 2060796  | L count: 783790\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# normalize text first\n",
    "pt = (df[\"p_throws\"]\n",
    "        .astype(\"string\")\n",
    "        .str.strip()\n",
    "        .str.upper())\n",
    "\n",
    "# binary flags (uint8 saves memory)\n",
    "df[\"is_R\"] = (pt == \"R\").astype(\"uint8\")\n",
    "df[\"is_L\"] = (pt == \"L\").astype(\"uint8\")\n",
    "\n",
    "# quick sanity checks\n",
    "print(df[[\"p_throws\",\"is_R\",\"is_L\"]].head(10))\n",
    "print(\"R count:\", int(df[\"is_R\"].sum()), \" | L count:\", int(df[\"is_L\"].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be748302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bat_is_R  is_R  is_L\n",
      "0         1     1     0\n",
      "1         1     1     0\n",
      "2         1     1     0\n",
      "3         1     1     0\n",
      "4         1     1     0\n",
      "5         1     1     0\n",
      "6         0     1     0\n",
      "7         1     1     0\n",
      "8         1     1     0\n",
      "9         1     1     0\n"
     ]
    }
   ],
   "source": [
    "st = (df[\"stand\"]\n",
    "        .astype(\"string\")\n",
    "        .str.strip()\n",
    "        .str.upper())\n",
    "\n",
    "df[\"bat_is_R\"] = (st == \"R\").astype(\"uint8\")\n",
    "df[\"bat_is_L\"] = (st == \"L\").astype(\"uint8\")\n",
    "print(df[[\"bat_is_R\",\"is_R\",\"is_L\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3d39773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.043\n",
       "1   -0.054\n",
       "2    0.058\n",
       "3    0.126\n",
       "4   -0.086\n",
       "5    0.365\n",
       "6    0.467\n",
       "7   -0.048\n",
       "8   -0.053\n",
       "9    0.034\n",
       "Name: delta_run_exp, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"delta_run_exp\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066322ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
