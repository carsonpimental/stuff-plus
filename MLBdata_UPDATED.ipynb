{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a141da58",
   "metadata": {},
   "source": [
    "Data Collection:\n",
    "\n",
    "-Using PyBaseball package to collect pitch data from 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63e0b0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cpim1\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "from pybaseball import statcast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4590f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import os\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "import io\n",
    "import sys\n",
    "import contextlib\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pybaseball import statcast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bf9c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Quiet mode\n",
    "# -------------------------------\n",
    "# Disable tqdm progress bars used internally\n",
    "os.environ[\"TQDM_DISABLE\"] = \"1\"\n",
    "# Silence pybaseball/pandas FutureWarnings etc.\n",
    "warnings.filterwarnings(\"ignore\", module=\"pybaseball\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _suppress_stdout_stderr():\n",
    "    \"\"\"Temporarily redirect stdout/stderr to devnull (tqdm writes to stderr).\"\"\"\n",
    "    with open(os.devnull, 'w') as devnull:\n",
    "        old_out, old_err = sys.stdout, sys.stderr\n",
    "        try:\n",
    "            sys.stdout = devnull\n",
    "            sys.stderr = devnull\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_out\n",
    "            sys.stderr = old_err\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Config\n",
    "# -------------------------------\n",
    "TRAIN_RANGES: List[Tuple[date, date]] = [\n",
    "    (date(2021, 4, 1),  date(2021, 10, 3)),\n",
    "    (date(2022, 4, 7),  date(2022, 10, 5)),\n",
    "    (date(2023, 3, 30), date(2023, 10, 1)),\n",
    "    (date(2024, 3, 28), date(2024, 9, 29)),\n",
    "]\n",
    "TEST_RANGES: List[Tuple[date, date]] = [\n",
    "    (date(2025, 3, 27), date(2025, 8, 31)),\n",
    "]\n",
    "\n",
    "CHUNK_DAYS = 5\n",
    "REQUEST_SLEEP_SEC = 1.0\n",
    "MAX_RETRIES = 3\n",
    "RETRY_SLEEP_SEC = 3.0\n",
    "\n",
    "OUTPUT_DIR = \"output\"\n",
    "TRAIN_OUT = os.path.join(OUTPUT_DIR, \"train.csv\")\n",
    "TEST_OUT  = os.path.join(OUTPUT_DIR, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c6332ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Utilities\n",
    "# -------------------------------\n",
    "def generate_chunks(start_date: date, end_date: date, span_days: int = CHUNK_DAYS) -> List[Tuple[date, date]]:\n",
    "    chunks = []\n",
    "    cur = start_date\n",
    "    delta = timedelta(days=span_days - 1)\n",
    "    while cur <= end_date:\n",
    "        nxt = min(cur + delta, end_date)\n",
    "        chunks.append((cur, nxt))\n",
    "        cur = nxt + timedelta(days=1)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def fetch_statcast_window(start_dt: str, end_dt: str) -> pd.DataFrame:\n",
    "    last_err = None\n",
    "    for _ in range(MAX_RETRIES):\n",
    "        try:\n",
    "            with _suppress_stdout_stderr():\n",
    "                return statcast(start_dt=start_dt, end_dt=end_dt)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(RETRY_SLEEP_SEC)\n",
    "    # On permanent failure return empty frame silently\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "def collect_ranges(ranges: List[Tuple[date, date]]) -> pd.DataFrame:\n",
    "    frames = []\n",
    "    for s, e in ranges:\n",
    "        for a, b in generate_chunks(s, e, CHUNK_DAYS):\n",
    "            df = fetch_statcast_window(a.strftime(\"%Y-%m-%d\"), b.strftime(\"%Y-%m-%d\"))\n",
    "            if df is not None and not df.empty:\n",
    "                frames.append(df)\n",
    "            time.sleep(REQUEST_SLEEP_SEC)\n",
    "    if not frames:\n",
    "        return pd.DataFrame()\n",
    "    out = pd.concat(frames, ignore_index=True)\n",
    "    if \"game_date\" in out.columns:\n",
    "        out[\"game_date\"] = pd.to_datetime(out[\"game_date\"], errors=\"coerce\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_vaa_row(row: pd.Series) -> float:\n",
    "    for k in (\"vy0\", \"ay\", \"vz0\", \"az\"):\n",
    "        if pd.isna(row.get(k)):\n",
    "            return np.nan\n",
    "    vy0, ay, vz0, az = row[\"vy0\"], row[\"ay\"], row[\"vz0\"], row[\"az\"]\n",
    "    if pd.isna(vy0) or pd.isna(ay) or pd.isna(vz0) or pd.isna(az) or ay == 0:\n",
    "        return np.nan\n",
    "    y0, yf = 50.0, 17.0 / 12.0\n",
    "    vy_f_sq = vy0**2 - 2.0 * ay * (y0 - yf)\n",
    "    if vy_f_sq < 0:\n",
    "        return np.nan\n",
    "    vy_f = -np.sqrt(vy_f_sq)\n",
    "    t = (vy_f - vy0) / ay\n",
    "    if not np.isfinite(t) or t <= 0:\n",
    "        return np.nan\n",
    "    vz_f = vz0 + az * t\n",
    "    if vy_f == 0:\n",
    "        return np.nan\n",
    "    return float(-np.degrees(np.arctan(vz_f / vy_f)))\n",
    "\n",
    "\n",
    "def add_vaa(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df[\"vaa\"] = df.apply(compute_vaa_row, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def sort_and_dedup(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    sort_cols = [c for c in [\"game_date\", \"game_pk\", \"at_bat_number\", \"pitch_number\"] if c in df.columns]\n",
    "    if sort_cols:\n",
    "        df = df.sort_values(sort_cols, kind=\"mergesort\")\n",
    "    dedup_keys = [c for c in [\"game_pk\", \"at_bat_number\", \"pitch_number\"] if c in df.columns]\n",
    "    if dedup_keys:\n",
    "        df = df.drop_duplicates(subset=dedup_keys, keep=\"first\")\n",
    "    else:\n",
    "        df = df.drop_duplicates(keep=\"first\")\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44628fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote 2,844,586 rows to output\\train.csv\n",
      "✅ Wrote 599,491 rows to output\\test.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Main\n",
    "# -------------------------------\n",
    "def main():\n",
    "    ensure_dir(TRAIN_OUT)\n",
    "    ensure_dir(TEST_OUT)\n",
    "\n",
    "    # TRAIN\n",
    "    train_df = collect_ranges(TRAIN_RANGES)\n",
    "    train_df = add_vaa(train_df)\n",
    "    train_df = sort_and_dedup(train_df)\n",
    "    train_df.to_csv(TRAIN_OUT, index=False)\n",
    "    print(f\"✅ Wrote {len(train_df):,} rows to {TRAIN_OUT}\")\n",
    "\n",
    "    # TEST\n",
    "    test_df = collect_ranges(TEST_RANGES)\n",
    "    test_df = add_vaa(test_df)\n",
    "    test_df = sort_and_dedup(test_df)\n",
    "    test_df.to_csv(TEST_OUT, index=False)\n",
    "    print(f\"✅ Wrote {len(test_df):,} rows to {TEST_OUT}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "654c98ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: c:\\Users\\cpim1\\Downloads\n",
      "File: C:\\Users\\cpim1\\Downloads\\output\\train.csv\n",
      "Exists? True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "print(\"CWD:\", Path.cwd())\n",
    "p = Path(\"output/train.csv\").resolve()\n",
    "print(\"File:\", p)\n",
    "print(\"Exists?\", p.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a275c86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pitch_type', 'game_date', 'release_speed', 'release_pos_x', 'release_pos_z', 'player_name', 'batter', 'pitcher', 'events', 'description', 'spin_dir', 'spin_rate_deprecated', 'break_angle_deprecated', 'break_length_deprecated', 'zone', 'des', 'game_type', 'stand', 'p_throws', 'home_team', 'away_team', 'type', 'hit_location', 'bb_type', 'balls', 'strikes', 'game_year', 'pfx_x', 'pfx_z', 'plate_x', 'plate_z', 'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot', 'hc_x', 'hc_y', 'tfs_deprecated', 'tfs_zulu_deprecated', 'umpire', 'sv_id', 'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az', 'sz_top', 'sz_bot', 'hit_distance_sc', 'launch_speed', 'launch_angle', 'effective_speed', 'release_spin_rate', 'release_extension', 'game_pk', 'fielder_2', 'fielder_3', 'fielder_4', 'fielder_5', 'fielder_6', 'fielder_7', 'fielder_8', 'fielder_9', 'release_pos_y', 'estimated_ba_using_speedangle', 'estimated_woba_using_speedangle', 'woba_value', 'woba_denom', 'babip_value', 'iso_value', 'launch_speed_angle', 'at_bat_number', 'pitch_number', 'pitch_name', 'home_score', 'away_score', 'bat_score', 'fld_score', 'post_away_score', 'post_home_score', 'post_bat_score', 'post_fld_score', 'if_fielding_alignment', 'of_fielding_alignment', 'spin_axis', 'delta_home_win_exp', 'delta_run_exp', 'bat_speed', 'swing_length', 'estimated_slg_using_speedangle', 'delta_pitcher_run_exp', 'hyper_speed', 'home_score_diff', 'bat_score_diff', 'home_win_exp', 'bat_win_exp', 'age_pit_legacy', 'age_bat_legacy', 'age_pit', 'age_bat', 'n_thruorder_pitcher', 'n_priorpa_thisgame_player_at_bat', 'pitcher_days_since_prev_game', 'batter_days_since_prev_game', 'pitcher_days_until_next_game', 'batter_days_until_next_game', 'api_break_z_with_gravity', 'api_break_x_arm', 'api_break_x_batter_in', 'arm_angle', 'attack_angle', 'attack_direction', 'swing_path_tilt', 'intercept_ball_minus_batter_pos_x_inches', 'intercept_ball_minus_batter_pos_y_inches', 'vaa']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"output/train.csv\")\n",
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee57800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CH', 'CS', 'CU', 'EP', 'FA', 'FC', 'FF', 'FO', 'FS', 'KC', 'KN', 'PO', 'SC', 'SI', 'SL', 'ST', 'SV']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_pitches = sorted(df[\"pitch_type\"].dropna().unique().tolist())\n",
    "print(unique_pitches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f912b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_CH', 'is_CS', 'is_CU', 'is_EP', 'is_FA', 'is_FC', 'is_FF', 'is_FO', 'is_FS', 'is_KC', 'is_KN', 'is_PO', 'is_SC', 'is_SI', 'is_SL', 'is_ST', 'is_SV']\n",
      "is_FF    947500.0\n",
      "is_SL    463669.0\n",
      "is_SI    439449.0\n",
      "is_CH    309410.0\n",
      "is_FC    216938.0\n",
      "is_CU    196785.0\n",
      "is_SV    143853.0\n",
      "is_FS     60817.0\n",
      "is_KC     59991.0\n",
      "is_EP      1769.0\n",
      "dtype: float64\n",
      "CH count: 309410\n"
     ]
    }
   ],
   "source": [
    "# Make \"is_[pitchtype]\" columns\n",
    "\n",
    "\n",
    "PITCH_TYPE_FLAGS = [\n",
    "    \"is_CH\",\"is_CS\",\"is_CU\",\"is_EP\",\"is_FA\",\"is_FC\",\"is_FF\",\"is_FO\",\"is_FS\",\n",
    "    \"is_KC\",\"is_KN\",\"is_PO\",\"is_SC\",\"is_SI\",\"is_SL\",\"is_ST\",\"is_SV\"\n",
    "]\n",
    "\n",
    "# optional: map ambiguous labels -> your canonical set\n",
    "_PITCH_MAP = {\n",
    "    \"FA\": \"FF\",   # four-seam\n",
    "    \"ST\": \"SV\",   # sweeper\n",
    "}\n",
    "\n",
    "def add_pitch_type_flags(df: pd.DataFrame, col: str = \"pitch_type\") -> pd.DataFrame:\n",
    "    # clean source column\n",
    "    pt = (df[col].astype(\"string\").str.strip().str.upper())\n",
    "    pt = pt.replace(_PITCH_MAP)  # normalize aliases\n",
    "\n",
    "    # one-hot to is_* names\n",
    "    dummies = pd.get_dummies(pt, prefix=\"is\", dtype=\"uint8\")\n",
    "\n",
    "    # ensure every desired flag column exists\n",
    "    for flag in PITCH_TYPE_FLAGS:\n",
    "        if flag not in dummies.columns:\n",
    "            dummies[flag] = 0\n",
    "\n",
    "    # keep only desired order\n",
    "    dummies = dummies[PITCH_TYPE_FLAGS]\n",
    "\n",
    "    # drop any existing is_* to avoid duplicates, then join fresh\n",
    "    df = df.drop(columns=[c for c in df.columns if c.startswith(\"is_\")], errors=\"ignore\").join(dummies)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ----- usage -----\n",
    "df = pd.read_csv(\"output/train.csv\")\n",
    "df = add_pitch_type_flags(df)\n",
    "\n",
    "# quick check\n",
    "print(PITCH_TYPE_FLAGS)  # your exact list/order\n",
    "print(df[PITCH_TYPE_FLAGS].sum().sort_values(ascending=False).head(10))\n",
    "# e.g. count of changeups:\n",
    "print(\"CH count:\", int(df[\"is_CH\"].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a3db599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint64(309410)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"is_CH\"].sum()  # changeups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b3bf8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  p_throws  is_R  is_L\n",
      "0        R     1     0\n",
      "1        R     1     0\n",
      "2        R     1     0\n",
      "3        R     1     0\n",
      "4        R     1     0\n",
      "5        R     1     0\n",
      "6        R     1     0\n",
      "7        R     1     0\n",
      "8        R     1     0\n",
      "9        R     1     0\n",
      "R count: 2060796  | L count: 783790\n"
     ]
    }
   ],
   "source": [
    "# Make columns for pitcher throwing hand\n",
    "\n",
    "# normalize text first\n",
    "pt = (df[\"p_throws\"]\n",
    "        .astype(\"string\")\n",
    "        .str.strip()\n",
    "        .str.upper())\n",
    "\n",
    "# binary flags (uint8 saves memory)\n",
    "df[\"is_R\"] = (pt == \"R\").astype(\"uint8\")\n",
    "df[\"is_L\"] = (pt == \"L\").astype(\"uint8\")\n",
    "\n",
    "# quick sanity checks\n",
    "print(df[[\"p_throws\",\"is_R\",\"is_L\"]].head(10))\n",
    "print(\"R count:\", int(df[\"is_R\"].sum()), \" | L count:\", int(df[\"is_L\"].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be748302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bat_is_R  is_R  is_L\n",
      "0         1     1     0\n",
      "1         1     1     0\n",
      "2         1     1     0\n",
      "3         1     1     0\n",
      "4         1     1     0\n",
      "5         1     1     0\n",
      "6         0     1     0\n",
      "7         1     1     0\n",
      "8         1     1     0\n",
      "9         1     1     0\n"
     ]
    }
   ],
   "source": [
    "# Make column for batter handedness\n",
    "st = (df[\"stand\"]\n",
    "        .astype(\"string\")\n",
    "        .str.strip()\n",
    "        .str.upper())\n",
    "\n",
    "df[\"bat_is_R\"] = (st == \"R\").astype(\"uint8\")\n",
    "df[\"bat_is_L\"] = (st == \"L\").astype(\"uint8\")\n",
    "print(df[[\"bat_is_R\",\"is_R\",\"is_L\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d701ca32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
