{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a141da58",
   "metadata": {},
   "source": [
    "Data Collection:\n",
    "\n",
    "-Using PyBaseball package to collect pitch data from 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea493ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote 2,844,586 rows to output\\train.csv\n",
      "✅ Wrote 599,491 rows to output\\test.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "import os\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "import io\n",
    "import sys\n",
    "import contextlib\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pybaseball import statcast\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Quiet mode\n",
    "# -------------------------------\n",
    "# Disable tqdm progress bars used internally\n",
    "os.environ[\"TQDM_DISABLE\"] = \"1\"\n",
    "# Silence pybaseball/pandas FutureWarnings etc.\n",
    "warnings.filterwarnings(\"ignore\", module=\"pybaseball\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _suppress_stdout_stderr():\n",
    "    \"\"\"Temporarily redirect stdout/stderr to devnull (tqdm writes to stderr).\"\"\"\n",
    "    with open(os.devnull, 'w') as devnull:\n",
    "        old_out, old_err = sys.stdout, sys.stderr\n",
    "        try:\n",
    "            sys.stdout = devnull\n",
    "            sys.stderr = devnull\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_out\n",
    "            sys.stderr = old_err\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Config\n",
    "# -------------------------------\n",
    "TRAIN_RANGES: List[Tuple[date, date]] = [\n",
    "    (date(2021, 4, 1),  date(2021, 10, 3)),\n",
    "    (date(2022, 4, 7),  date(2022, 10, 5)),\n",
    "    (date(2023, 3, 30), date(2023, 10, 1)),\n",
    "    (date(2024, 3, 28), date(2024, 9, 29)),\n",
    "]\n",
    "TEST_RANGES: List[Tuple[date, date]] = [\n",
    "    (date(2025, 3, 27), date(2025, 8, 31)),\n",
    "]\n",
    "\n",
    "CHUNK_DAYS = 5\n",
    "REQUEST_SLEEP_SEC = 1.0\n",
    "MAX_RETRIES = 3\n",
    "RETRY_SLEEP_SEC = 3.0\n",
    "\n",
    "OUTPUT_DIR = \"output\"\n",
    "TRAIN_OUT = os.path.join(OUTPUT_DIR, \"train.csv\")\n",
    "TEST_OUT  = os.path.join(OUTPUT_DIR, \"test.csv\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Utilities\n",
    "# -------------------------------\n",
    "def generate_chunks(start_date: date, end_date: date, span_days: int = CHUNK_DAYS) -> List[Tuple[date, date]]:\n",
    "    chunks = []\n",
    "    cur = start_date\n",
    "    delta = timedelta(days=span_days - 1)\n",
    "    while cur <= end_date:\n",
    "        nxt = min(cur + delta, end_date)\n",
    "        chunks.append((cur, nxt))\n",
    "        cur = nxt + timedelta(days=1)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def fetch_statcast_window(start_dt: str, end_dt: str) -> pd.DataFrame:\n",
    "    last_err = None\n",
    "    for _ in range(MAX_RETRIES):\n",
    "        try:\n",
    "            with _suppress_stdout_stderr():\n",
    "                return statcast(start_dt=start_dt, end_dt=end_dt)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(RETRY_SLEEP_SEC)\n",
    "    # On permanent failure return empty frame silently\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "def collect_ranges(ranges: List[Tuple[date, date]]) -> pd.DataFrame:\n",
    "    frames = []\n",
    "    for s, e in ranges:\n",
    "        for a, b in generate_chunks(s, e, CHUNK_DAYS):\n",
    "            df = fetch_statcast_window(a.strftime(\"%Y-%m-%d\"), b.strftime(\"%Y-%m-%d\"))\n",
    "            if df is not None and not df.empty:\n",
    "                frames.append(df)\n",
    "            time.sleep(REQUEST_SLEEP_SEC)\n",
    "    if not frames:\n",
    "        return pd.DataFrame()\n",
    "    out = pd.concat(frames, ignore_index=True)\n",
    "    if \"game_date\" in out.columns:\n",
    "        out[\"game_date\"] = pd.to_datetime(out[\"game_date\"], errors=\"coerce\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_vaa_row(row: pd.Series) -> float:\n",
    "    for k in (\"vy0\", \"ay\", \"vz0\", \"az\"):\n",
    "        if pd.isna(row.get(k)):\n",
    "            return np.nan\n",
    "    vy0, ay, vz0, az = row[\"vy0\"], row[\"ay\"], row[\"vz0\"], row[\"az\"]\n",
    "    if pd.isna(vy0) or pd.isna(ay) or pd.isna(vz0) or pd.isna(az) or ay == 0:\n",
    "        return np.nan\n",
    "    y0, yf = 50.0, 17.0 / 12.0\n",
    "    vy_f_sq = vy0**2 - 2.0 * ay * (y0 - yf)\n",
    "    if vy_f_sq < 0:\n",
    "        return np.nan\n",
    "    vy_f = -np.sqrt(vy_f_sq)\n",
    "    t = (vy_f - vy0) / ay\n",
    "    if not np.isfinite(t) or t <= 0:\n",
    "        return np.nan\n",
    "    vz_f = vz0 + az * t\n",
    "    if vy_f == 0:\n",
    "        return np.nan\n",
    "    return float(-np.degrees(np.arctan(vz_f / vy_f)))\n",
    "\n",
    "\n",
    "def add_vaa(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df[\"vaa\"] = df.apply(compute_vaa_row, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def sort_and_dedup(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    sort_cols = [c for c in [\"game_date\", \"game_pk\", \"at_bat_number\", \"pitch_number\"] if c in df.columns]\n",
    "    if sort_cols:\n",
    "        df = df.sort_values(sort_cols, kind=\"mergesort\")\n",
    "    dedup_keys = [c for c in [\"game_pk\", \"at_bat_number\", \"pitch_number\"] if c in df.columns]\n",
    "    if dedup_keys:\n",
    "        df = df.drop_duplicates(subset=dedup_keys, keep=\"first\")\n",
    "    else:\n",
    "        df = df.drop_duplicates(keep=\"first\")\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Main\n",
    "# -------------------------------\n",
    "def main():\n",
    "    ensure_dir(TRAIN_OUT)\n",
    "    ensure_dir(TEST_OUT)\n",
    "\n",
    "    # TRAIN\n",
    "    train_df = collect_ranges(TRAIN_RANGES)\n",
    "    train_df = add_vaa(train_df)\n",
    "    train_df = sort_and_dedup(train_df)\n",
    "    train_df.to_csv(TRAIN_OUT, index=False)\n",
    "    print(f\"✅ Wrote {len(train_df):,} rows to {TRAIN_OUT}\")\n",
    "\n",
    "    # TEST\n",
    "    test_df = collect_ranges(TEST_RANGES)\n",
    "    test_df = add_vaa(test_df)\n",
    "    test_df = sort_and_dedup(test_df)\n",
    "    test_df.to_csv(TEST_OUT, index=False)\n",
    "    print(f\"✅ Wrote {len(test_df):,} rows to {TEST_OUT}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
